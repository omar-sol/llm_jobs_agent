{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "def flatten_dict(d, parent_key='', sep='_', parent_keys=set()):\n",
    "    items = []\n",
    "    for k, v in d.items():\n",
    "        # Check if key is unique in the context of parent keys\n",
    "        new_key = k if (k not in parent_keys) else f'{parent_key}{sep}{k}' if parent_key else k\n",
    "        if isinstance(v, dict):\n",
    "            # Update the set of parent keys for the next level\n",
    "            new_parent_keys = parent_keys.union(set(d.keys()))\n",
    "            items.extend(flatten_dict(v, new_key, sep, new_parent_keys).items())\n",
    "        else:\n",
    "            items.append((new_key, v))\n",
    "    return dict(items)\n",
    "\n",
    "def read_jsonl_and_flatten(file_path):\n",
    "    flattened_data = []\n",
    "    with open(file_path, 'r') as file:\n",
    "        for line in file:\n",
    "            # Load the line as a JSON object\n",
    "            data_dict = json.loads(line)\n",
    "            # Flatten the dictionary\n",
    "            flattened_dict = flatten_dict(data_dict)\n",
    "            \n",
    "            # Might be better to clean this in another function\n",
    "            # Check if the dictionary has the right number of keys\n",
    "            if len(flattened_dict.keys()) != 34:\n",
    "                print(\"Skipping due to wrong number of keys\")\n",
    "                print(flattened_dict.keys())\n",
    "                print(flattened_dict)\n",
    "                continue \n",
    "\n",
    "            if flattened_dict[\"jobs_towardsai_url\"] == 'nan':\n",
    "                print(\"Skipping due to nan url\")\n",
    "                print(flattened_dict)\n",
    "                continue\n",
    "            \n",
    "            # Add the flattened dictionary to the list\n",
    "            flattened_data.append(flattened_dict)\n",
    "\n",
    "    return flattened_data\n",
    "\n",
    "# Example usage\n",
    "file_path = '../data/formatted_jobs_feb5_24_results.jsonl'\n",
    "flattened_data = read_jsonl_and_flatten(file_path)\n",
    "print(\"end of file\")\n",
    "print(flattened_data[0])\n",
    "print(len(flattened_data[0].keys()))\n",
    "print(flattened_data[9].keys())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "def optimize_keys(data_dict):\n",
    "    # Function to check if a value is valid (not None, Nan, empty string, or 'Not Specified')\n",
    "\n",
    "    def is_valid(value):\n",
    "        # Check for None\n",
    "        if value is None:\n",
    "            return False\n",
    "\n",
    "        # Check for NaN for float values\n",
    "        if isinstance(value, float) and math.isnan(value):\n",
    "            return False\n",
    "\n",
    "        # Check for empty strings and lists\n",
    "        if value == \"\" or value == []:\n",
    "            return False\n",
    "\n",
    "        # Case-insensitive check for specific strings\n",
    "        if isinstance(value, str) and value.lower() in [\"nan\", \"not specified\"]:\n",
    "            return False\n",
    "\n",
    "        # If value is a list, check each item\n",
    "        if isinstance(value, list):\n",
    "            for item in value:\n",
    "                # Check if the item is a string and matches the specified values\n",
    "                if isinstance(item, str) and item.lower() in [\"nan\", \"not specified\"]:\n",
    "                    return False\n",
    "\n",
    "        return True\n",
    "\n",
    "    # Optimize 'city' and 'country'\n",
    "    # If location_city is valid use it ('country'='JP\" and location_country='Japan')\n",
    "    for key in [\"city\", \"country\"]:\n",
    "        location_model_key = f\"location_model_{key}\"\n",
    "        # if not is_valid(data_dict.get(key)) and is_valid(\n",
    "        #     data_dict.get(location_model_key)\n",
    "        # ):\n",
    "        if is_valid(data_dict.get(location_model_key)):\n",
    "            data_dict[key] = data_dict[location_model_key]\n",
    "        data_dict.pop(location_model_key, None)\n",
    "\n",
    "    # Optimize 'ai' and 'involves_ai'\n",
    "    if data_dict.get(\"ai\") not in [0, 1] and is_valid(data_dict.get(\"involves_ai\")):\n",
    "        data_dict[\"ai\"] = 1 if data_dict[\"involves_ai\"] else 0\n",
    "    data_dict.pop(\"involves_ai\", None)\n",
    "    if data_dict.get(\"ai\") in [0, 1]:\n",
    "        data_dict[\"ai\"] = bool(data_dict[\"ai\"])\n",
    "\n",
    "    # Optimize 'salary_numerical'\n",
    "    salary = data_dict.get(\"salary_numerical\")\n",
    "    print(\"salary\", salary)\n",
    "    if not is_valid(salary) or isinstance(salary, str):\n",
    "        data_dict[\"salary_min\"] = data_dict[\"salary_max\"] = None\n",
    "    elif (\n",
    "        isinstance(salary, list)\n",
    "        and len(salary) == 1\n",
    "        and is_valid(salary[0])\n",
    "        and salary[0] < 900000\n",
    "        and salary[0] > 5\n",
    "    ):\n",
    "        data_dict[\"salary_min\"] = data_dict[\"salary_max\"] = salary[0]\n",
    "    elif (\n",
    "        isinstance(salary, list)\n",
    "        and len(salary) == 2\n",
    "        and all(is_valid(val) for val in salary)\n",
    "        and all(val < 900000 for val in salary)\n",
    "        and all(val > 5 for val in salary)\n",
    "    ):\n",
    "        data_dict[\"salary_min\"], data_dict[\"salary_max\"] = salary\n",
    "    else:\n",
    "        data_dict[\"salary_min\"] = data_dict[\"salary_max\"] = None\n",
    "\n",
    "    print(\"salary_min\", data_dict[\"salary_min\"])\n",
    "    print(\"salary_max\", data_dict[\"salary_max\"])\n",
    "    print(\"salary_frequency\", data_dict[\"salary_frequency\"], \"\\n\")\n",
    "    data_dict.pop(\"salary_numerical\", None)\n",
    "\n",
    "    # Optimize 'job_skills'\n",
    "    if is_valid(data_dict.get(\"required_skills\")) and not is_valid(data_dict.get(\"skills\")):\n",
    "        data_dict[\"skills\"] = data_dict[\"required_skills\"]\n",
    "    elif is_valid(data_dict.get(\"skills\")):\n",
    "        data_dict[\"skills\"] = data_dict.get(\"skills\").split(\",\")\n",
    "    data_dict.pop(\"required_skills\", None)\n",
    "\n",
    "    # Optimize 'experience_years'\n",
    "    if is_valid(data_dict.get(\"experience_years\")):\n",
    "        experience_years = data_dict[\"experience_years\"]\n",
    "        if isinstance(experience_years, str):\n",
    "            data_dict[\"experience_years\"] = None\n",
    "        else:\n",
    "            data_dict[\"experience_years\"] = int(experience_years)\n",
    "\n",
    "    # Replace 'Not specified' with None for all keys\n",
    "    for key, value in data_dict.items():\n",
    "        if not is_valid(value):\n",
    "            data_dict[key] = None\n",
    "\n",
    "    # Transform lists into strings\n",
    "    for key, value in data_dict.items():\n",
    "        if isinstance(value, list):\n",
    "            data_dict[key] = \", \".join(value) if len(value) > 1 else value[0]\n",
    "\n",
    "    # Transform values into lowercase strings\n",
    "    lowercased_data = {\n",
    "        key: value.lower() if isinstance(value, str) else value\n",
    "        for key, value in data_dict.items()\n",
    "    }\n",
    "\n",
    "    return lowercased_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_of_dicts = []\n",
    "for i, dict in enumerate(flattened_data):\n",
    "    print(\"index\", i)\n",
    "    optimized_dict = optimize_keys(dict)\n",
    "    list_of_dicts.append(optimized_dict)\n",
    "\n",
    "# print(list_of_dicts[8978].keys())\n",
    "print(list_of_dicts[8978])\n",
    "# for i, dict in enumerate(list_of_dicts):\n",
    "# print(list_of_dicts[2])\n",
    "# print(dict.keys())\n",
    "# if i == 5:\n",
    "# break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import tiktoken\n",
    "import logging\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "# The data in a dataframe\n",
    "df1 = pd.DataFrame(list_of_dicts)\n",
    "df1 = df1.rename(columns={\"ai\": \"involves_ai\"})\n",
    "df1 = df1.rename(columns={\"title\": \"job_title\"})\n",
    "df1 = df1.rename(columns={\"skills\": \"job_skills\"})\n",
    "\n",
    "df1['created_at'] = pd.to_datetime(df1['created_at'])\n",
    "df1 = df1.rename(columns={\"created_at\": \"creation_date\"})\n",
    "\n",
    "# df1 = df1.rename(columns={\"cleaned_description\": \"job_listing_text\"})\n",
    "df1 = df1.drop(\n",
    "    [\"slug\", \"approved\", \"chain_of_thought\", \"job_type_reasoning\", \"remote_reasoning\"],\n",
    "    axis=1,\n",
    ")\n",
    "\n",
    "def num_tokens_from_string(string: str, encoding_name: str) -> int:\n",
    "    \"\"\"Returns the number of tokens in a text string.\"\"\"\n",
    "    try:\n",
    "        encoding = tiktoken.get_encoding(encoding_name)\n",
    "        num_tokens = len(encoding.encode(string))\n",
    "        return num_tokens\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Error calculating number of tokens: {e}\")\n",
    "        return 0\n",
    "\n",
    "df1[\"num_tokens\"] = df1[\"job_listing_text\"].apply(\n",
    "        lambda x: num_tokens_from_string(x, \"cl100k_base\")\n",
    "    )\n",
    "\n",
    "# # Finding and printing the max value in the salary_max column\n",
    "# max_salary_max = df1['salary_max'].max()\n",
    "# print(f\"Maximum value in 'salary_max' column: {max_salary_max}\")\n",
    "\n",
    "# # Finding and printing the min value in the salary_min column\n",
    "# min_salary_min = df1['salary_min'].min()\n",
    "# print(f\"Minimum value in 'salary_min' column: {min_salary_min}\")\n",
    "\n",
    "# # Print the row with the max salary_max value\n",
    "# print(\"Row with the maximum 'salary_max' value:\")\n",
    "# print(df1[df1['salary_max'] == max_salary_max])\n",
    "\n",
    "# # Print the row with the min salary_min value\n",
    "# print(\"\\nRow with the minimum 'salary_min' value:\")\n",
    "# print(df1[df1['salary_min'] == min_salary_min])\n",
    "\n",
    "# print(df1.head(1))\n",
    "# print(df1.dtypes)\n",
    "# print(\"\\n\")\n",
    "print(df1.info())\n",
    "# print(df1.shape)\n",
    "# print(df1.columns)\n",
    "# print(len(df1))\n",
    "\n",
    "# df1.to_pickle(\"../data/extracted_cleaned_df_feb5.pkl\")\n",
    "# print(df1.to_markdown())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 7907 entries, 0 to 7906\n",
      "Data columns (total 20 columns):\n",
      " #   Column                   Non-Null Count  Dtype         \n",
      "---  ------                   --------------  -----         \n",
      " 0   job_id                   7907 non-null   int64         \n",
      " 1   created_at               7907 non-null   datetime64[ns]\n",
      " 2   job_title                7907 non-null   object        \n",
      " 3   job_skills               7907 non-null   object        \n",
      " 4   job_type                 7907 non-null   object        \n",
      " 5   company_id               7907 non-null   int64         \n",
      " 6   apply_url                7907 non-null   object        \n",
      " 7   city                     7907 non-null   object        \n",
      " 8   country                  7907 non-null   object        \n",
      " 9   salary                   7907 non-null   object        \n",
      " 10  salary_min               7907 non-null   int64         \n",
      " 11  salary_max               7907 non-null   int64         \n",
      " 12  salary_currency          7907 non-null   object        \n",
      " 13  url_slug                 7907 non-null   object        \n",
      " 14  role_description         7907 non-null   object        \n",
      " 15  company_name             7907 non-null   object        \n",
      " 16  company_description      7907 non-null   object        \n",
      " 17  cleaned_description      7907 non-null   object        \n",
      " 18  scraped_skills_required  7907 non-null   object        \n",
      " 19  scraped_skills_useful    7907 non-null   object        \n",
      "dtypes: datetime64[ns](1), int64(4), object(15)\n",
      "memory usage: 1.2+ MB\n",
      "None\n",
      "['Full Time' 'Remote,Full Time' 'Internship' 'Remote' 'Type - Permanent'\n",
      " 'Onsite' 'Data' '' 'Back-End - Python' 'Intern' 'Freelancer'\n",
      " 'Office based' 'Computer Vision' 'DevOps / SRE' 'Backend'\n",
      " 'Remote,Freelancer' 'On-roll' 'Full Time,Freelancer' 'Full Time,Onsite'\n",
      " 'Remote,Full Time,Onsite' 'Permanent' 'CDI Cadre,on-site' 'CDI Cadre'\n",
      " 'All work types' 'Temporary' 'Cyber Excepted Service' 'FT' 'Regular'\n",
      " 'Remote,Internship' 'Fixed Term' 'Remote,Onsite'\n",
      " 'Remote,Full Time,Freelancer' 'Teilzeit' 'A jornada completa' 'Vollzeit'\n",
      " 'Teljes munkaidő' 'Voltijds' 'Heltid' 'Stage' 'Part Time'\n",
      " 'Remote,Part Time' 'Mid-Senior Level' 'Regular,on-site' 'on-site'\n",
      " 'Systems Administrators' 'Freelancer,Temporary' 'CDD' 'Hybrid'\n",
      " 'Full Time,Internship' '#LI-Hybrid' 'Software & Database Engineers'\n",
      " 'Cloud Engineers' 'Remote,Temporary' 'Full Time,Temporary'\n",
      " 'Remote,Part Time,Full Time' 'Other' 'Freelancer,Onsite'\n",
      " 'Contingent Hire' 'Co-op' '3.  ' 'Full Time,Freelancer,Temporary'\n",
      " 'LI-Hybrid' 'Remote,Full Time,Internship' 'Hybrid, Menlo Park' 'Hourly'\n",
      " 'Payroll' '(No information provided)' 'Período integral; remoto primeiro'\n",
      " 'Full Time,Freelancer,Internship' 'Full Time,Freelancer,Temporary,Onsite'\n",
      " 'Any' 'CDI - Permanent' '(Leave Blank)' 'Employee' 'Early Careers'\n",
      " 'Part Time,Freelancer' 'Intern - Grad/PhD' 'ST Fellowships'\n",
      " 'Full Time,Freelancer,Onsite' 'Mid Level' 'Corporate' 'On-site'\n",
      " 'Full Time,Internship,Temporary' 'Contingent Worker'\n",
      " 'Remote,Full Time,Temporary' 'Unavailable'\n",
      " 'Consultant (STTA, TOR, SOW, EOI)' 'Temporary,Onsite' 'Working Student'\n",
      " '(Unavailable)' 'Part Time,Full Time' 'In-office' 'Business Analyst'\n",
      " 'Remote,Part Time,Freelancer,Temporary' 'Full - Time' 'Back-End - Java'\n",
      " 'Machine Learning' 'Freelancer,Internship' 'Internship,Temporary'\n",
      " 'Part Time,Temporary' 'Project Based' '(Leave blank)']\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_json(\"db_info.json\")\n",
    "print(df.info())\n",
    "# print(df.head(1))\n",
    "\n",
    "# Get all unique values in the 'job_type' column\n",
    "unique_job_types = df['job_type'].unique()\n",
    "\n",
    "# Print the unique job types\n",
    "print(unique_job_types)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
